{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7997f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Neural_Network:\n",
    "    # Initialize the network\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs, hidden_layer_weights, output_layer_weights, learning_rate):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "        self.hidden_layer_weights = hidden_layer_weights\n",
    "        self.output_layer_weights = output_layer_weights\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    # Calculate neuron activation for an input\n",
    "    def sigmoid(self, inputs):\n",
    "        \n",
    "        output = 1/(1 + np.exp(-inputs))\n",
    "        return output\n",
    "\n",
    "    def forward_pass(self, inputs):\n",
    "        hidden_layer_outputs = []\n",
    "        hidden_biases = [-0.02,-0.2]\n",
    "        for i in range(self.num_hidden): #2\n",
    "            weighted_sum = 0.\n",
    "            for j in range(len(self.hidden_layer_weights)): #4\n",
    "                weighted_sum += inputs[j] * self.hidden_layer_weights[j][i]\n",
    "            weighted_sum += hidden_biases[i]\n",
    "            output = self.sigmoid(weighted_sum)\n",
    "            hidden_layer_outputs.append(output)\n",
    "\n",
    "        output_layer_outputs = []\n",
    "        output_biases = [-0.33,0.26,0.06]\n",
    "        for i in range(self.num_outputs): #3\n",
    "            # TODO! Calculate the weighted sum, and then compute the final output.\n",
    "            weighted_sum = 0.\n",
    "            for j in range(len(self.output_layer_weights)):#2\n",
    "                weighted_sum += hidden_layer_outputs[j] * self.output_layer_weights[j][i]\n",
    "            weighted_sum += output_biases[i]\n",
    "            output = self.sigmoid(weighted_sum)\n",
    "            output_layer_outputs.append(output)\n",
    "        return hidden_layer_outputs, output_layer_outputs\n",
    "\n",
    "    # Backpropagate error and store in neurons\n",
    "    def backward_propagate_error(self, inputs, hidden_layer_outputs, output_layer_outputs, desired_outputs):\n",
    "\n",
    "        output_layer_betas = np.zeros(self.num_outputs)\n",
    "        # TODO! Calculate output layer betas.\n",
    "        for i in range(self.num_outputs):\n",
    "            output_layer_betas[i] = desired_outputs[i] - output_layer_outputs[i]\n",
    "        #print('OL betas: ', output_layer_betas)\n",
    "\n",
    "        hidden_layer_betas = np.zeros(self.num_hidden)\n",
    "        for i in range (self.num_hidden): \n",
    "            for j in range(self.num_outputs):\n",
    "                hidden_layer_betas[i] += self.output_layer_weights[i][j] * output_layer_outputs[j] * (1 - output_layer_outputs[j]) * output_layer_betas[j] \n",
    "        # TODO! Calculate hidden layer betas.\n",
    "        #print('HL betas: ', hidden_layer_betas)\n",
    "\n",
    "        # This is a HxO array (H hidden nodes, O outputs)\n",
    "        delta_output_layer_weights = np.zeros((self.num_hidden, self.num_outputs))\n",
    "        # TODO! Calculate output layer weight changes.\n",
    "        for i in range(self.num_hidden):\n",
    "            for j in range(self.num_outputs):\n",
    "                delta_output_layer_weights[i][j] = self.learning_rate * hidden_layer_outputs[i] * output_layer_outputs[j] * (1 - output_layer_outputs[j] ) * output_layer_betas[j] \n",
    "        \n",
    "        # This is a IxH array (I inputs, H hidden nodes)\n",
    "        delta_hidden_layer_weights = np.zeros((self.num_inputs, self.num_hidden))\n",
    "        # TODO! Calculate hidden layer weight changes.\n",
    "        for i in range(self.num_inputs):\n",
    "            for j in range(self.num_hidden):\n",
    "                delta_hidden_layer_weights[i][j] = self.learning_rate * inputs[i] * hidden_layer_outputs[j] * ( 1 - hidden_layer_outputs[j]) * hidden_layer_betas[j] \n",
    "       \n",
    "        # Return the weights we calculated, so they can be used to update all the weights.\n",
    "        return delta_output_layer_weights, delta_hidden_layer_weights\n",
    "\n",
    "    def update_weights(self, delta_output_layer_weights, delta_hidden_layer_weights):\n",
    "        # TODO! Update the weights.\n",
    "        self.hidden_layer_weights += delta_hidden_layer_weights\n",
    "        self.output_layer_weights += delta_output_layer_weights\n",
    "\n",
    "        #print('Placeholder')\n",
    "\n",
    "    def train(self, instances, desired_outputs, epochs):\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print('epoch = ', epoch)\n",
    "            predictions = []\n",
    "            for i, instance in enumerate(instances):\n",
    "                hidden_layer_outputs, output_layer_outputs = self.forward_pass(instance)\n",
    "                delta_output_layer_weights, delta_hidden_layer_weights, = self.backward_propagate_error(\n",
    "                    instance, hidden_layer_outputs, output_layer_outputs, desired_outputs[i])\n",
    "                predicted_class = np.argmax(output_layer_outputs)   # TODO!\n",
    "                predictions.append(predicted_class)\n",
    "\n",
    "                # We use online learning, i.e. update the weights after every instance.\n",
    "                self.update_weights(delta_output_layer_weights, delta_hidden_layer_weights)\n",
    "\n",
    "            # Print new weights\n",
    "            #print('Hidden layer weights \\n', self.hidden_layer_weights)\n",
    "            #print('Output layer weights  \\n', self.output_layer_weights)\n",
    "\n",
    "            # TODO: Print accuracy achieved over this epoch\n",
    "            acc = 0\n",
    "            for i in range(len(predictions)):\n",
    "                if predictions[i] == np.argmax(desired_outputs[i]):\n",
    "                    acc+=1\n",
    "            print('Accuracy in train set = ', acc/len(desired_outputs))\n",
    "\n",
    "    def predict(self, instances):\n",
    "        predictions = []\n",
    "        for instance in instances:\n",
    "            hidden_layer_outputs, output_layer_outputs = self.forward_pass(instance)\n",
    "            #print(output_layer_outputs)\n",
    "            predicted_class = np.argmax(output_layer_outputs)  # TODO! Should be 0, 1, or 2.\n",
    "            predictions.append(predicted_class)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a85c1b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First instance has label Adelie, which is [0] as an integer, and [1. 0. 0.] as a list of outputs.\n",
      "\n",
      "Predicted label for the first instance is: ['Chinstrap']\n",
      "\n",
      "epoch =  0\n",
      "Accuracy in train set =  0.0\n",
      "Weights after performing BP for first instance only:\n",
      "Hidden layer weights:\n",
      " [[-0.28056275 -0.21970523]\n",
      " [ 0.07826717  0.20090767]\n",
      " [-0.30124328  0.32065123]\n",
      " [ 0.09932855  0.01035171]]\n",
      "Output layer weights:\n",
      " [[-0.27633516  0.01659626  0.1982984 ]\n",
      " [ 0.09427539  0.11599737 -0.37222444]]\n",
      "epoch =  0\n",
      "Accuracy in train set =  0.4552238805970149\n",
      "epoch =  1\n",
      "Accuracy in train set =  0.48507462686567165\n",
      "epoch =  2\n",
      "Accuracy in train set =  0.5\n",
      "epoch =  3\n",
      "Accuracy in train set =  0.5783582089552238\n",
      "epoch =  4\n",
      "Accuracy in train set =  0.6791044776119403\n",
      "epoch =  5\n",
      "Accuracy in train set =  0.746268656716418\n",
      "epoch =  6\n",
      "Accuracy in train set =  0.7873134328358209\n",
      "epoch =  7\n",
      "Accuracy in train set =  0.7947761194029851\n",
      "epoch =  8\n",
      "Accuracy in train set =  0.7947761194029851\n",
      "epoch =  9\n",
      "Accuracy in train set =  0.7947761194029851\n",
      "epoch =  10\n",
      "Accuracy in train set =  0.7947761194029851\n",
      "epoch =  11\n",
      "Accuracy in train set =  0.7947761194029851\n",
      "epoch =  12\n",
      "Accuracy in train set =  0.7947761194029851\n",
      "epoch =  13\n",
      "Accuracy in train set =  0.7947761194029851\n",
      "epoch =  14\n",
      "Accuracy in train set =  0.7947761194029851\n",
      "epoch =  15\n",
      "Accuracy in train set =  0.7947761194029851\n",
      "epoch =  16\n",
      "Accuracy in train set =  0.7985074626865671\n",
      "epoch =  17\n",
      "Accuracy in train set =  0.7985074626865671\n",
      "epoch =  18\n",
      "Accuracy in train set =  0.7985074626865671\n",
      "epoch =  19\n",
      "Accuracy in train set =  0.7985074626865671\n",
      "epoch =  20\n",
      "Accuracy in train set =  0.7985074626865671\n",
      "epoch =  21\n",
      "Accuracy in train set =  0.8059701492537313\n",
      "epoch =  22\n",
      "Accuracy in train set =  0.8097014925373134\n",
      "epoch =  23\n",
      "Accuracy in train set =  0.8171641791044776\n",
      "epoch =  24\n",
      "Accuracy in train set =  0.8171641791044776\n",
      "epoch =  25\n",
      "Accuracy in train set =  0.8283582089552238\n",
      "epoch =  26\n",
      "Accuracy in train set =  0.8283582089552238\n",
      "epoch =  27\n",
      "Accuracy in train set =  0.832089552238806\n",
      "epoch =  28\n",
      "Accuracy in train set =  0.8395522388059702\n",
      "epoch =  29\n",
      "Accuracy in train set =  0.8395522388059702\n",
      "epoch =  30\n",
      "Accuracy in train set =  0.8432835820895522\n",
      "epoch =  31\n",
      "Accuracy in train set =  0.8432835820895522\n",
      "epoch =  32\n",
      "Accuracy in train set =  0.8432835820895522\n",
      "epoch =  33\n",
      "Accuracy in train set =  0.8432835820895522\n",
      "epoch =  34\n",
      "Accuracy in train set =  0.8507462686567164\n",
      "epoch =  35\n",
      "Accuracy in train set =  0.8544776119402985\n",
      "epoch =  36\n",
      "Accuracy in train set =  0.8619402985074627\n",
      "epoch =  37\n",
      "Accuracy in train set =  0.8619402985074627\n",
      "epoch =  38\n",
      "Accuracy in train set =  0.8619402985074627\n",
      "epoch =  39\n",
      "Accuracy in train set =  0.8656716417910447\n",
      "epoch =  40\n",
      "Accuracy in train set =  0.8656716417910447\n",
      "epoch =  41\n",
      "Accuracy in train set =  0.8656716417910447\n",
      "epoch =  42\n",
      "Accuracy in train set =  0.8694029850746269\n",
      "epoch =  43\n",
      "Accuracy in train set =  0.8731343283582089\n",
      "epoch =  44\n",
      "Accuracy in train set =  0.8768656716417911\n",
      "epoch =  45\n",
      "Accuracy in train set =  0.8768656716417911\n",
      "epoch =  46\n",
      "Accuracy in train set =  0.8805970149253731\n",
      "epoch =  47\n",
      "Accuracy in train set =  0.8805970149253731\n",
      "epoch =  48\n",
      "Accuracy in train set =  0.8843283582089553\n",
      "epoch =  49\n",
      "Accuracy in train set =  0.8880597014925373\n",
      "epoch =  50\n",
      "Accuracy in train set =  0.8880597014925373\n",
      "epoch =  51\n",
      "Accuracy in train set =  0.8880597014925373\n",
      "epoch =  52\n",
      "Accuracy in train set =  0.8880597014925373\n",
      "epoch =  53\n",
      "Accuracy in train set =  0.8880597014925373\n",
      "epoch =  54\n",
      "Accuracy in train set =  0.8880597014925373\n",
      "epoch =  55\n",
      "Accuracy in train set =  0.8917910447761194\n",
      "epoch =  56\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  57\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  58\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  59\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  60\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  61\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  62\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  63\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  64\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  65\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  66\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  67\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  68\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  69\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  70\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  71\n",
      "Accuracy in train set =  0.8955223880597015\n",
      "epoch =  72\n",
      "Accuracy in train set =  0.8992537313432836\n",
      "epoch =  73\n",
      "Accuracy in train set =  0.8992537313432836\n",
      "epoch =  74\n",
      "Accuracy in train set =  0.8992537313432836\n",
      "epoch =  75\n",
      "Accuracy in train set =  0.8992537313432836\n",
      "epoch =  76\n",
      "Accuracy in train set =  0.8992537313432836\n",
      "epoch =  77\n",
      "Accuracy in train set =  0.9029850746268657\n",
      "epoch =  78\n",
      "Accuracy in train set =  0.9029850746268657\n",
      "epoch =  79\n",
      "Accuracy in train set =  0.9029850746268657\n",
      "epoch =  80\n",
      "Accuracy in train set =  0.9029850746268657\n",
      "epoch =  81\n",
      "Accuracy in train set =  0.9067164179104478\n",
      "epoch =  82\n",
      "Accuracy in train set =  0.9067164179104478\n",
      "epoch =  83\n",
      "Accuracy in train set =  0.9067164179104478\n",
      "epoch =  84\n",
      "Accuracy in train set =  0.9067164179104478\n",
      "epoch =  85\n",
      "Accuracy in train set =  0.9067164179104478\n",
      "epoch =  86\n",
      "Accuracy in train set =  0.9067164179104478\n",
      "epoch =  87\n",
      "Accuracy in train set =  0.9067164179104478\n",
      "epoch =  88\n",
      "Accuracy in train set =  0.9104477611940298\n",
      "epoch =  89\n",
      "Accuracy in train set =  0.9104477611940298\n",
      "epoch =  90\n",
      "Accuracy in train set =  0.914179104477612\n",
      "epoch =  91\n",
      "Accuracy in train set =  0.914179104477612\n",
      "epoch =  92\n",
      "Accuracy in train set =  0.914179104477612\n",
      "epoch =  93\n",
      "Accuracy in train set =  0.914179104477612\n",
      "epoch =  94\n",
      "Accuracy in train set =  0.914179104477612\n",
      "epoch =  95\n",
      "Accuracy in train set =  0.914179104477612\n",
      "epoch =  96\n",
      "Accuracy in train set =  0.914179104477612\n",
      "epoch =  97\n",
      "Accuracy in train set =  0.917910447761194\n",
      "epoch =  98\n",
      "Accuracy in train set =  0.917910447761194\n",
      "epoch =  99\n",
      "Accuracy in train set =  0.917910447761194\n",
      "\n",
      "After training:\n",
      "Hidden layer weights:\n",
      " [[ -2.26420111 -10.88648616]\n",
      " [ -8.14815943   5.65280866]\n",
      " [  3.13224798  -1.29228614]\n",
      " [  3.9457565    1.95532896]]\n",
      "Output layer weights:\n",
      " [[ -6.17249613  -3.97649849   4.29907339]\n",
      " [  4.73362019  -3.63421374 -11.27601845]]\n",
      "Accuracy in test set: =  1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def encode_labels(labels):\n",
    "    # encode 'Adelie' as 1, 'Chinstrap' as 2, 'Gentoo' as 3\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(labels)\n",
    "    # don't worry about this\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "\n",
    "    # encode 1 as [1, 0, 0], 2 as [0, 1, 0], and 3 as [0, 0, 1] (to fit with our network outputs!)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "    return label_encoder, integer_encoded, onehot_encoder, onehot_encoded\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = pd.read_csv('penguins307-train.csv')\n",
    "    # the class label is last!\n",
    "    labels = data.iloc[:, -1]\n",
    "    # seperate the data from the labels\n",
    "    instances = data.iloc[:, :-1]\n",
    "    #scale features to [0,1] to improve training\n",
    "    scaler = MinMaxScaler()\n",
    "    instances = scaler.fit_transform(instances)\n",
    "    # We can't use strings as labels directly in the network, so need to do some transformations\n",
    "    label_encoder, integer_encoded, onehot_encoder, onehot_encoded = encode_labels(labels)\n",
    "    #labels = onehot_encoded\n",
    "\n",
    "    # Parameters. As per the handout.\n",
    "    n_in = 4\n",
    "    n_hidden = 2\n",
    "    n_out = 3\n",
    "    learning_rate = 0.2\n",
    "\n",
    "    initial_hidden_layer_weights = np.array([[-0.28, -0.22], [0.08, 0.20], [-0.30, 0.32], [0.10, 0.01]])\n",
    "    initial_output_layer_weights = np.array([[-0.29, 0.03, 0.21], [0.08, 0.13, -0.36]])\n",
    "\n",
    "    nn = Neural_Network(n_in, n_hidden, n_out, initial_hidden_layer_weights, initial_output_layer_weights,\n",
    "                        learning_rate)\n",
    "\n",
    "    print('First instance has label {}, which is {} as an integer, and {} as a list of outputs.\\n'.format(\n",
    "        labels[0], integer_encoded[0], onehot_encoded[0]))\n",
    "\n",
    "    # need to wrap it into a 2D array\n",
    "    instance1_prediction = nn.predict([instances[0]])\n",
    "    if instance1_prediction[0] is None:\n",
    "        # This should never happen once you have implemented the feedforward.\n",
    "        instance1_predicted_label = \"???\"\n",
    "    else:\n",
    "        instance1_predicted_label = label_encoder.inverse_transform(instance1_prediction)\n",
    "    print('Predicted label for the first instance is: {}\\n'.format(instance1_predicted_label))\n",
    "\n",
    "    # TODO: Perform a single backpropagation pass using the first instance only. (In other words, train with 1\n",
    "    #  instance for 1 epoch!). Hint: you will need to first get the weights from a forward pass.\n",
    "    nn.train([instances[0]], [onehot_encoded[0]], 1)\n",
    "    print('Weights after performing BP for first instance only:')\n",
    "    print('Hidden layer weights:\\n', nn.hidden_layer_weights)\n",
    "    print('Output layer weights:\\n', nn.output_layer_weights)\n",
    "\n",
    "    #TODO: Train for 100 epochs, on all instances.\n",
    "    nn.train(instances,onehot_encoded , 100)\n",
    "\n",
    "    print('\\nAfter training:')\n",
    "    print('Hidden layer weights:\\n', nn.hidden_layer_weights)\n",
    "    print('Output layer weights:\\n', nn.output_layer_weights)\n",
    "\n",
    "    pd_data_ts = pd.read_csv('penguins307-test.csv')\n",
    "    test_labels = pd_data_ts.iloc[:, -1]\n",
    "    test_instances = pd_data_ts.iloc[:, :-1]\n",
    "    #scale the test according to our training data.\n",
    "    test_instances = scaler.fit_transform(test_instances)\n",
    "    pred = nn.predict(test_instances)\n",
    "    test_label_encoder, test_integer_encoded, test_onehot_encoder, test_onehot_encoded = encode_labels(test_labels)\n",
    "    test_labels = test_onehot_encoded\n",
    "    acc = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == np.argmax(test_labels[i]):\n",
    "            acc+=1\n",
    "    print('Accuracy in test set: = ', acc/len(test_labels))\n",
    "     #TODO: Compute and print the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6801f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
